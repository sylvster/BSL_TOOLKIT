{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network to Distinguish Power Density Graphs\n",
    "\n",
    "This repository contains the code to train and export a neural network that takes in an input of a Power Density Function (PDF) file and output a value between 0 and 1. A value closer to 1 indicates that the function contains inaccuracies that may need to be reviewed, and values closer to 0 means that there are no apparent inaccuracies."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prerequisites\n",
    "\n",
    "The following code heavily utilizes the Pytorch library. If unfamiliar with Pytorch or fundamental machine learning concepts, please review the following links before attempting to modify the code:\n",
    "\n",
    "[3Blue1Brown's Introduction to Deep Learning](https://www.youtube.com/playlist?list=PLZHQObOWTQDNU6R1_67000Dx_ZCJB-3pi)\n",
    "\n",
    "[Pytorch Tutorial - What is torch.nn really?](https://pytorch.org/tutorials/beginner/nn_tutorial.html)\n",
    "\n",
    "[Pytorch Tutorial - Beginner Basics](https://pytorch.org/tutorials/beginner/basics/intro.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "from torch import nn\n",
    "\n",
    "import os\n",
    "\n",
    "from tqdm import tqdm\n",
    "\n",
    "import sys"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For debugging purposes - prints the full values of numpy arrays and pytorch tensors\n",
    "\n",
    "# np.set_printoptions(threshold=sys.maxsize)\n",
    "# torch.set_printoptions(threshold=sys.maxsize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code creates a [custom dataset](https://pytorch.org/tutorials/beginner/basics/data_tutorial.html) that is used to load data for both the training and validation set. The current repository must contain a folder for training data and a folder for validation, with each file named after numbers starting from 0 (0, 1, 2...).\n",
    "\n",
    "Each PDF file inside both the training and validation data must follow the format of a PDF analysis generated by data center stations. An example called `PDFanalysis.2023.001.pdf` is attached for reference. The data format is then decoded using `np.fromfile`, and the probability values are then extracted for modifications.\n",
    "\n",
    "For the sake of simplicity in labeling, all correct PDF files have been named after an even number, while all incorrect PDF files have been named after an odd number. Hence, all correct PDF files will have the label of 0 and incorrect the label of 1 when mod 2 is applied."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PDFDataset(Dataset):\n",
    "    def __init__(self, is_training):\n",
    "        correct_path = \"/home/gcl/TT/sylvesterseo/bsl/BSL_TOOLKIT/strongmotion_ml/data/correct\"\n",
    "        incorrect_path = \"/home/gcl/TT/sylvesterseo/bsl/BSL_TOOLKIT/strongmotion_ml/data/incorrect\"\n",
    "        \n",
    "        self.data = {}\n",
    "\n",
    "        # Correct data: 0, 2, 4, ...\n",
    "        # Incorrect data: 1, 3, 5, ...\n",
    "        self.files = [item for pair in zip(sorted(os.listdir(correct_path)), sorted(os.listdir(incorrect_path))) for item in pair]\n",
    "        self.length = 0\n",
    "        print(self.files)\n",
    "\n",
    "        initial_index = 0 if is_training else 2\n",
    "        counter = 0\n",
    "        for i in tqdm(range(initial_index, len(self.files), 4)):\n",
    "            print(i)\n",
    "            correct_arr = np.fromfile(f\"{correct_path}/{self.files[i]}\", sep=\" \")[2::3]\n",
    "            incorrect_arr = np.fromfile(f\"{incorrect_path}/{self.files[i + 1]}\", sep=\" \")[2::3]\n",
    "            self.data[counter] = torch.from_numpy(correct_arr).float()\n",
    "            self.data[counter + 1] = torch.from_numpy(incorrect_arr).float() \n",
    "            counter += 2\n",
    "            self.length += 2\n",
    "        \n",
    "        print(self.data)\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        return self.data[i], torch.tensor(i % 2).reshape((1, )).float()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['0', 'BK.BRIB.01.HNN.2024.049.pdf', '1', 'BK.BRIB.01.HNN.2024.056.pdf', '2', 'BK.BRIB.01.HNN.2024.063.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:00<00:00, 57.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "4\n",
      "{0: tensor([]), 1: tensor([0., 0., 0.,  ..., 0., 0., 0.]), 2: tensor([]), 3: tensor([0., 0., 0.,  ..., 0., 0., 0.])}\n",
      "['0', 'BK.BRIB.01.HNN.2024.049.pdf', '1', 'BK.BRIB.01.HNN.2024.056.pdf', '2', 'BK.BRIB.01.HNN.2024.063.pdf']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00, 56.64it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "{0: tensor([]), 1: tensor([0., 0., 0.,  ..., 0., 0., 0.])}\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "training_data = PDFDataset(True)\n",
    "validation_data = PDFDataset(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(training_data, batch_size=2, shuffle=True)\n",
    "test_dataloader = DataLoader(validation_data, batch_size=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network\n",
    "\n",
    "The following [neural network](https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html) utilizes linear transformations for training. Future prospect includes the implementation of a convolutional neural network in an attempt to detect common patterns present among correct PDF files.\n",
    "\n",
    "The input value is a 122 by 151 tensor, which are all the probability values present within a PDF analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear_relu_stack = nn.Sequential(\n",
    "            nn.Linear(122 * 151, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.linear_relu_stack(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = NeuralNetwork()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training\n",
    "\n",
    "Functions for training and validating the models are defined below. This is the back propagation part of machine learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_loop(dataloader, model, loss_fn, optimizer):\n",
    "    size = len(dataloader.dataset)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for batch, (X, y) in enumerate(dataloader):\n",
    "        pred = model(X)\n",
    "        loss = loss_fn(pred, y)\n",
    "\n",
    "        #Backward propagation\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        if batch % 100 == 0:\n",
    "            loss, current = loss.item(), batch * batch_size + len(X)\n",
    "            print(f\"loss: {loss:>7f} [{current:>5d}/{size:>5d}]\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_loop(dataloader, model, loss_fn):\n",
    "    model.eval()\n",
    "    size = len(dataloader.dataset)\n",
    "    num_batches = len(dataloader)\n",
    "    test_loss, correct = 0, 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for X, y in dataloader:\n",
    "            pred = model(X)\n",
    "            test_loss += loss_fn(pred, y).item()\n",
    "            correct += (pred.round() == y).type(torch.float).sum().item()\n",
    "\n",
    "    test_loss /= num_batches\n",
    "    correct /= size\n",
    "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The learning rate affects how much impact each iteration has on the neural network; high learning rate will transform the neural network more per iteration, while low learning rate transforms it less.\n",
    "\n",
    "Batch size indicates how many pieces of data (in this case, PDF files) are used per one instance of training. It has been set to 2 currently due to the low number of training data available.\n",
    "\n",
    "In one epoch, the machine iterates through all of the training data available. Ten epochs indicate that the machine will be iterating through the training data for a total of ten times, with each one shuffled in a unique way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-2\n",
    "batch_size = 2\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_fn = nn.BCELoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for t in range(epochs):\n",
    "    print(f\"Epoch {t + 1}\\n----------------------------------\")\n",
    "    train_loop(train_dataloader, model, loss_fn, optimizer)\n",
    "    test_loop(test_dataloader, model, loss_fn)\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exporting Data\n",
    "\n",
    "After the model is trained and ready to go, it can then be exported for use by other programs. To see an example of how to use an exported model weights, check out [the BSL analysis toolkit](https://github.com/sylvster/BSL-ML-ANALYZE), a program that uses this model's parameters to separate batches of PDF data into correct and incorrect bins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'model_weights.pth')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
